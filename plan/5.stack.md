Thatâ€™s a **very solid, modern choice** ğŸ‘
Prisma + Neon + oRPC fits your product _extremely_ well, and it keeps the architecture **clean, typed, and future-proof**.

Iâ€™ll explain **why this works**, how to **structure it**, and what to **watch out for**â€”without overengineering.

---

# âœ… Why Prisma + Neon + oRPC is a great fit

### 1ï¸âƒ£ Prisma + Neon

Perfect for your domain because:

- Skills, roles, assessments, gaps = **relational**
- Skill graph = **recursive queries**
- Career analytics = **SQL-friendly**
- Neon free tier = generous + serverless-ready

Youâ€™re building a **knowledge-heavy system**, not just app state.

---

### 2ï¸âƒ£ oRPC (excellent call)

oRPC gives you:

- End-to-end **type safety**
- No REST boilerplate
- Clear backend contracts
- Excellent fit for **Next.js App Router**

This is especially important because:

- AI outputs must be validated
- Skill gap logic must be deterministic
- Frontend should _trust_ backend shapes

---

# ğŸ§± Recommended Architecture

```
Next.js (App Router)
â”œâ”€ app/
â”‚  â”œâ”€ (routes)
â”‚  â”œâ”€ actions/
â”‚  â””â”€ api/orpc/
â”‚
â”œâ”€ server/
â”‚  â”œâ”€ db/        (Prisma + Neon)
â”‚  â”œâ”€ orpc/      (procedures)
â”‚  â”œâ”€ ai/        (LLM logic)
â”‚  â””â”€ services/ (domain logic)
â”‚
â””â”€ shared/
   â””â”€ types/     (Zod schemas)
```

---

# ğŸ§  Data responsibilities

### Neon + Prisma (single source of truth)

- users
- skills (hard + soft)
- roles
- skill prerequisites
- assessments
- assessment results
- skill gaps
- resources (links)

No duplication.

---

### AI is **stateless**

- Takes structured input
- Returns structured output (validated with Zod)
- Never owns data

---

# ğŸ”Œ oRPC usage (how it fits)

### Example procedure categories

```
/orpc
 â”œâ”€ user/
 â”‚   â”œâ”€ getProfile
 â”‚   â””â”€ updateGoal
 â”œâ”€ assessment/
 â”‚   â”œâ”€ start
 â”‚   â”œâ”€ submitAnswer
 â”‚   â””â”€ finalize
 â”œâ”€ skills/
 â”‚   â”œâ”€ getGraph
 â”‚   â””â”€ getGaps
 â”œâ”€ report/
 â”‚   â””â”€ generate
 â””â”€ advisor/
     â””â”€ chat
```

Frontend imports procedures **with full typing**.

---

## Example oRPC procedure (simplified)

```ts
export const submitAnswer = procedure
  .input(
    z.object({
      assessmentId: z.string(),
      answer: z.string(),
    })
  )
  .mutation(async ({ input, ctx }) => {
    const evaluation = await evaluateWithAI(input.answer);
    return {
      score: evaluation.score,
      confidence: evaluation.confidence,
    };
  });
```

Frontend gets:

```ts
const result = await orpc.assessment.submitAnswer(...)
```

Typed. Safe. Clean.

---

# ğŸ§ª Skill Graph in Postgres (Prisma-friendly)

You can model the graph like this:

```prisma
model Skill {
  id          String   @id @default(uuid())
  name        String
  category    SkillCategory
  domain      String
  prerequisites SkillRelation[] @relation("Prerequisites")
}

model SkillRelation {
  id           String @id @default(uuid())
  fromSkillId  String
  toSkillId    String
  strength     Float

  fromSkill Skill @relation("Prerequisites", fields: [fromSkillId], references: [id])
  toSkill   Skill @relation("RequiredBy", fields: [toSkillId], references: [id])
}
```

Then use **recursive CTEs** via `prisma.$queryRaw`.

---

# ğŸ¤– AI Layer (Important with oRPC)

**Never expose raw AI output.**

Flow:

1. oRPC procedure calls AI
2. AI returns JSON
3. Validate with Zod
4. Store structured result
5. Return typed response

This avoids:

- hallucinations
- breaking frontend types
- runtime crashes

---

# ğŸ†“ Free Tier Reality Check

| Component | Free Tier | OK?       |
| --------- | --------- | --------- |
| Neon      | âœ…        | Yes       |
| Prisma    | âœ…        | Yes       |
| oRPC      | âœ…        | Yes       |
| Next.js   | âœ…        | Yes       |
| OpenAI    | âš ï¸        | Low usage |

You can stay **under â‚¬10/month** for a long time.

---

# âš ï¸ Trade-offs (honest)

### Downsides

- No built-in realtime like Convex
- More schema upfront
- Recursive SQL requires care

### Upsides

- Clean domain model
- Strong typing everywhere
- Easier B2B / HR expansion
- Easier audits & reports

For _this product_, **upsides win**.

---

**AI SDK v6 + Groq free models (Kimi 2)** is _exactly_ the right call for:

- fast iteration
- low cost / free tier
- structured outputs
- streaming UX
- future model portability

Iâ€™ll explain **why this fits perfectly**, then show **how to wire it cleanly with oRPC + Prisma**, and what **patterns to use / avoid**.

---

## âœ… Why AI SDK v6 fits your architecture

AI SDK v6 is no longer â€œjust chatâ€. Itâ€™s a **typed AI orchestration layer**, which matches your goals perfectly.

### Key reasons itâ€™s a great fit

- **Model-agnostic** â†’ switch Groq â†” OpenAI later
- **Structured outputs** â†’ essential for skill scoring
- **Streaming** â†’ AI advisor UX
- **Tool calling** â†’ gap reasoning, not just text
- **Server-first** â†’ works perfectly in Next.js App Router

This is _not_ overkill â€” itâ€™s the right abstraction.

---

## ğŸ§  Groq + Kimi 2 (Free Tier) â€” Reality Check

### Why Groq is ideal early on

- Very fast inference
- Generous free tier
- Open / permissive models
- Good reasoning for:

  - classification
  - evaluation
  - summarization
  - structured extraction

### Where Kimi 2 works well

- Skill assessment evaluation
- Soft skill scenario scoring
- Gap explanation
- Resource ranking
- Advisor-style reasoning

### Where itâ€™s weaker

- Long multi-hour reasoning chains
- Complex math proofs

ğŸ‘‰ For MVP: **perfectly fine**.

---

## ğŸ§± Clean AI Architecture (Strongly Recommended)

```
/server/ai
â”œâ”€ models.ts        // Groq + Kimi config
â”œâ”€ prompts/
â”‚  â”œâ”€ assessSkill.ts
â”‚  â”œâ”€ calibrateConfidence.ts
â”‚  â”œâ”€ explainGap.ts
â”‚  â””â”€ recommendResources.ts
â”œâ”€ schemas/
â”‚  â”œâ”€ skillScore.schema.ts
â”‚  â”œâ”€ gapExplanation.schema.ts
â”‚  â””â”€ resourceList.schema.ts
â””â”€ index.ts
```

**Rule**

> AI never touches Prisma directly.
> AI returns JSON â†’ validated â†’ stored.

---

## ğŸ§ª Example: Skill Assessment with AI SDK v6

### 1ï¸âƒ£ Define schema (Zod)

```ts
export const SkillEvaluationSchema = z.object({
  skillId: z.string(),
  level: z.number().min(0).max(5),
  confidence: z.number().min(0).max(1),
  notes: z.string(),
});
```

---

### 2ï¸âƒ£ AI call (AI SDK v6 + Groq)

```ts
import { generateObject } from "ai";
import { groq } from "@ai-sdk/groq";

export async function evaluateSkill(input: {
  skillName: string;
  question: string;
  answer: string;
}) {
  return generateObject({
    model: groq("kimi2"),
    schema: SkillEvaluationSchema,
    prompt: `
You are a senior career assessor.

Skill: ${input.skillName}
Question: ${input.question}
User answer: ${input.answer}

Evaluate the user's skill objectively.
    `,
    temperature: 0.3,
  });
}
```

âœ” Typed
âœ” Validated
âœ” Cheap
âœ” Fast

---

## ğŸ”Œ Integrating with oRPC (Best Practice)

### oRPC procedure

```ts
export const submitAssessment = procedure
  .input(z.object({
    assessmentId: z.string(),
    answer: z.string(),
  }))
  .mutation(async ({ input, ctx }) => {
    const skill = await ctx.db.skill.findUnique(...)

    const result = await evaluateSkill({
      skillName: skill.name,
      question: skill.question,
      answer: input.answer,
    })

    await ctx.db.skillResult.create({
      data: {
        skillId: skill.id,
        level: result.level,
        confidence: result.confidence,
        notes: result.notes,
      },
    })

    return result
  })
```

Frontend receives **typed, clean data**.

---

## ğŸ’¬ AI Advisor Chat (Streaming)

Use `streamText()` from AI SDK v6:

- context = skill gaps + role
- tools = `explainGap`, `suggestNextStep`
- model = Kimi 2

This makes chat **actually useful**, not generic.

---

## ğŸ§  Tool Calling Pattern (Power Move)

Example tools:

- `getSkillGap(skillId)`
- `rankGaps()`
- `recommendResources(skillId)`

LLM reasons â†’ calls tools â†’ assembles answer.

This avoids hallucination and keeps logic deterministic.

---

## ğŸ†“ Cost Control (Important)

### Rules to stay free

- Short prompts
- Structured outputs
- No raw chat history â†’ summarize
- Cache evaluations per user+skill
- Temperature low

With Groq free tier, you can support **hundreds of users/month**.

---

## âš ï¸ Common Mistakes to Avoid

âŒ Letting AI write DB queries
âŒ Returning raw text to frontend
âŒ Using chat for scoring
âŒ Overusing embeddings early
âŒ Treating soft skills as â€œfluffâ€

Youâ€™re avoiding all of these ğŸ‘

---

## ğŸ§­ Recommended next step

Youâ€™re at a **very strong architectural foundation**.

Next, I strongly suggest:

1. **Define Zod schemas for all AI outputs**
2. Design **Prisma schema aligned to AI**
3. Create **first 5 assessment prompts**
4. Implement **1 end-to-end assessment flow**
5. Add **gap ranking SQL**

If you want, say **â€œDesign the Prisma schemaâ€** or **â€œDesign AI promptsâ€** and weâ€™ll go straight into code-level detail ğŸš€
